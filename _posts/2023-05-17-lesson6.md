# FastAI Course Lesson 6
## Random Forests
The key findings from Lesson 6 (Random Forests) of the FastAI course are the following:
1. Decision Trees:
* *gini* can be used to evaluate how good a split is. In other words - if you grab two items at random from the dataset, what are the chances they are from the same dataset.
* Decision trees have a *maximum depth*. Which refers to the number of splits.
* `sklearn` has a `DecisionTreeClassifier` that can be used to easily create these models.
* An example of a decision tree can be seen below:
**TODO: INSERT DECISION TREE IMAGE HERE**

2. Random forests:
* Works by using bagging with many decision tree models.
* By taking the average of the predictions of the uncorrelated, unbiased models - better results *should* be obtained.
* `sklearn` has a `RandomForestClassifier` that can be used to easily create these models.
* 
